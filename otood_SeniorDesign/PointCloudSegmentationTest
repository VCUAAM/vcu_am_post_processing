import pyrealsense2 as rs
import numpy as np
import torch
import open3d as o3d
from learning3d.models.segmentation import Segmentation
from learning3d.models.pointnet import PointNet

# Initialize the RealSense pipeline
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
pipeline.start(config)

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load the PointNet model
feature_model = PointNet(global_feat=False)
segmentation_model = Segmentation(feature_model=feature_model, num_classes=4).to(device)

# Load pretrained weights
pretrained_weights_path = "best_ptnet_model.pth"  # Update to the correct path
try:
    segmentation_model.load_state_dict(torch.load(pretrained_weights_path, map_location=device))
    print("Pretrained weights loaded successfully.")
except FileNotFoundError:
    print("Pretrained weights not found. Using randomly initialized weights.")

# Helper function to preprocess the point cloud
def preprocess_pointcloud(points):
    mean = np.mean(points, axis=0)
    points -= mean
    max_val = np.max(np.linalg.norm(points, axis=1))
    points /= max_val
    return points

# Main processing loop
try:
    while True:
        # Fetch frames
        frames = pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()

        if not depth_frame or not color_frame:
            continue

        # Generate point cloud
        pc = rs.pointcloud()
        points = pc.calculate(depth_frame)
        verts = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)

        if verts.shape[0] == 0:
            print("Empty point cloud. Skipping this frame.")
            continue

        # Preprocess the point cloud
        preprocessed_points = preprocess_pointcloud(verts)

        # Convert to PyTorch tensor and reshape
        input_data = torch.tensor(preprocessed_points, dtype=torch.float32).to(device)
        input_data = input_data.T.unsqueeze(0)  # Transpose to [3 x NumInPoints] and add batch dimension

        print(f"Input data shape: {input_data.shape}")  # Debugging

        # Perform segmentation
        with torch.no_grad():
            output = segmentation_model(input_data)
            predicted_labels = torch.argmax(output, dim=2).squeeze(0).cpu().numpy()

        # Visualize segmented point cloud
        color_map = {
            0: [1, 0, 0],  # Red
            1: [0, 1, 0],  # Green
            2: [0, 0, 1],  # Blue
            3: [1, 1, 0],  # Yellow
        }

        segmented_colors = np.array([color_map[label] for label in predicted_labels])
        segmented_colors = (segmented_colors * 255).astype(np.uint8)

        point_cloud = o3d.geometry.PointCloud()
        point_cloud.points = o3d.utility.Vector3dVector(verts)
        point_cloud.colors = o3d.utility.Vector3dVector(segmented_colors / 255.0)

        o3d.visualization.draw_geometries([point_cloud])

finally:
    pipeline.stop()
