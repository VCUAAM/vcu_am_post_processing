import pyrealsense2 as rs  # Intel RealSense SDK
import numpy as np
import cv2
import time

# Create a pipeline object for streaming and processing frames
pipeline = rs.pipeline()

# Configure the pipeline to automatically select a device
config = rs.config()

# Enable the depth stream at 1280x720 resolution, 30 frames per second (fps)
config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)

# Start the pipeline
pipeline.start(config)

# Time tracker to trigger a snapshot every 5 seconds
last_snapshot_time = time.time()
snapshot_interval = 5  # seconds

try:
    while True:
        # Wait for a coherent set of frames (depth and color) without blocking
        frames = pipeline.wait_for_frames()

        # Get the depth frame
        depth_frame = frames.get_depth_frame()
        if not depth_frame:
            continue

        # Get the current time
        current_time = time.time()

        # If 5 seconds have passed, take a snapshot and check the distance
        if current_time - last_snapshot_time >= snapshot_interval:
            # Get the depth frame's width and height
            width = depth_frame.get_width()
            height = depth_frame.get_height()

            # Get the distance at the center of the frame
            dist_to_center = depth_frame.get_distance(int(width / 2), int(height / 2))

            # Print the distance to the object in the center
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] The camera is facing an object {dist_to_center:.3f} meters away")

            # Convert the depth frame to a numpy array
            depth_image = np.asanyarray(depth_frame.get_data())

            # Scale depth values for visualization
            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

            # Display the depth frame using OpenCV (you can close this by pressing 'q')
            cv2.imshow('Depth Snapshot', depth_colormap)

            # Update the last snapshot time
            last_snapshot_time = current_time

        # Keep the depth stream running in the background
        cv2.imshow('Live Depth Stream', cv2.applyColorMap(cv2.convertScaleAbs(np.asanyarray(depth_frame.get_data()), alpha=0.03), cv2.COLORMAP_JET))

        # Check if 'q' key is pressed to exit
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

finally:
    # Stop the pipeline when done
    pipeline.stop()
    cv2.destroyAllWindows()
