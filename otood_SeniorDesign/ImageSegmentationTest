import pyrealsense2 as rs
import numpy as np
import torch
import torch.nn as nn
import cv2
from sklearn.preprocessing import StandardScaler

# Define a simple PointNet-like model for segmentation
class PointNetSegmentation(nn.Module):
    def __init__(self, num_classes):
        super(PointNetSegmentation, self).__init__()
        self.fc1 = nn.Linear(3, 64)
        self.fc2 = nn.Linear(64, 128)
        self.fc3 = nn.Linear(128, 256)
        self.fc4 = nn.Linear(256, num_classes)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# Configure RealSense pipeline
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# Start streaming
pipeline.start(config)

# Initialize the segmentation model
num_classes = 5  # Example: 5 distinct object classes
model = PointNetSegmentation(num_classes)
model.eval()  # Set model to evaluation mode

# Helper function to preprocess point cloud
def preprocess_pointcloud(verts):
    scaler = StandardScaler()
    verts = scaler.fit_transform(verts)
    return torch.tensor(verts, dtype=torch.float32)

# Visualization function
def visualize_segmentation(point_cloud, labels, image_shape):
    colors = np.random.randint(0, 255, (num_classes, 3))
    output_image = np.zeros((image_shape[0], image_shape[1], 3), dtype=np.uint8)

    for point, label in zip(point_cloud, labels):
        x, y, z = point
        if z > 0:  # Ensure valid points
            px, py = int(x * 320 + 320), int(y * 240 + 240)
            color = colors[label]
            cv2.circle(output_image, (px, py), 1, color.tolist(), -1)

    return output_image

try:
    while True:
        # Wait for frames
        frames = pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()

        if not depth_frame or not color_frame:
            continue

        # Generate point cloud
        pc = rs.pointcloud()
        points = pc.calculate(depth_frame)
        verts = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)

        # Preprocess point cloud
        input_data = preprocess_pointcloud(verts)

        # Run segmentation
        with torch.no_grad():
            logits = model(input_data)
            predictions = torch.argmax(logits, dim=1).numpy()

        # Visualize segmentation
        color_image = np.asanyarray(color_frame.get_data())
        segmented_image = visualize_segmentation(verts, predictions, color_image.shape)

        # Display results
        cv2.imshow('Color Image', color_image)
        cv2.imshow('Segmented Point Cloud', segmented_image)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
finally:
    pipeline.stop()
    cv2.destroyAllWindows()
